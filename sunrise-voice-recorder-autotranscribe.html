<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Sunrise Voice Recorder (Web)</title>
<!-- MP3 encoder (pure client-side). If this CDN is blocked, you can swap to another or serve locally. -->
<script src="https://cdn.jsdelivr.net/npm/lamejs@1.2.1/lame.min.js"></script>
<style>
  :root{
    --bg:#FFF7ED;      /* peach-cream */
    --card:#FFEAD5;    /* soft peach */
    --ring:#FED7AA;    /* orange-200 */
    --text:#7C2D12;    /* warm brown for contrast */
    --muted:#9A623B;
    --accent:#FDE68A;  /* warm yellow */
    --accent2:#FCA5A5; /* soft red */
    --accent3:#93C5FD; /* soft sky */
  }
  *{box-sizing:border-box}
  html,body{height:100%}
  body{
    margin:0; display:grid; place-items:center; background:var(--bg);
    font:16px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;
    color:var(--text);
  }
  .card{
    width:min(92vw,720px); background:var(--card);
    border:2px solid var(--ring); border-radius:18px; padding:20px;
    box-shadow:0 12px 40px rgba(124,45,18,.12);
  }
  h1{margin:0 0 6px; font-size:1.6rem}
  p.sub{margin:0 0 18px; color:var(--muted)}
  .row{display:flex; gap:12px; flex-wrap:wrap; align-items:center}
  button{
    appearance:none; border:none; border-radius:12px; padding:12px 16px; cursor:pointer;
    font-weight:650; box-shadow:0 8px 24px rgba(124,45,18,.12); transition:transform .06s ease, filter .15s ease;
  }
  button:hover{filter:brightness(1.04)}
  button:active{transform:translateY(1px)}
  button[disabled]{opacity:.6; cursor:not-allowed; filter:grayscale(.2)}
  #startBtn{background:var(--accent)}
  #stopBtn{background:var(--accent2)}
  #saveBtn{background:var(--accent3); color:#0B2545}
  .status{min-height:28px; margin:10px 0 6px; font-variant-numeric:tabular-nums}
  .timer{font-size:2rem; font-weight:800; letter-spacing:.5px}
  .meter{
    height:10px; width:100%; background:rgba(255,255,255,.6); border-radius:999px;
    border:1px solid rgba(255,255,255,.8); overflow:hidden;
  }
  .meter > span{display:block; height:100%; width:0%; background:linear-gradient(90deg,#FDE68A,#FDBA74,#FCA5A5)}
  .error{color:#B91C1C; min-height:1.2em}
  footer{margin-top:12px; color:var(--muted); font-size:.9rem}
</style>
</head>
<body>
  <main class="card" role="application" aria-labelledby="title">
    <h1 id="title">Sunrise Voice Recorder</h1>
    <p class="sub">Click <b>Start Recording</b>, talk as long as you want, then <b>Stop</b> and <b>Download MP3</b>.</p>

    <div class="row" style="justify-content:space-between">
      <div class="status" id="status">Idle</div>
      <div class="timer" id="timer">00:00</div>
    </div>

    <div class="meter" aria-hidden="true"><span id="level"></span></div>

    <div style="height:12px"></div>

    <div class="row">
      <button id="startBtn" type="button">▶ Start Recording</button>
      <button id="stopBtn" type="button" disabled>⏹ Stop Recording</button>
      <button id="saveBtn" type="button" disabled>⬇ Download MP3</button>
    </div>

    <div style="height:8px"></div>
    <audio id="player" controls hidden></audio>
    <div id="err" class="error" role="status" aria-live="polite"></div>

    <footer>Note: Most browsers require <b>https://</b> or <b>http://localhost</b> for microphone access.</footer>
  </main>

<script>
(async function () {
  const startBtn = document.getElementById('startBtn');
  const stopBtn  = document.getElementById('stopBtn');
  const saveBtn  = document.getElementById('saveBtn');

  const statusEl = document.getElementById('status');
  const timerEl  = document.getElementById('timer');
  const levelBar = document.getElementById('level');
  const player   = document.getElementById('player');
  const errEl    = document.getElementById('err');

  let mediaStream = null;
  let audioCtx = null;
  let sourceNode = null;
  let workletNode = null;
  let scriptProcessor = null; // fallback
  let recording = false;

  let sampleRate = 44100;
  let channels = 1;
  let startTimeMs = 0;
  let timerId = null;

  // We'll accumulate Float32 samples in chunks; flatten when stopped
  const chunks = [];
  let approxLevel = 0;

  function setStatus(msg){ statusEl.textContent = msg; }
  function setError(msg){ errEl.textContent = msg || ''; }
  function fmt(ms){
    const t = Math.floor(ms/1000);
    const m = String(Math.floor(t/60)).padStart(2,'0');
    const s = String(t%60).padStart(2,'0');
    return `${m}:${s}`;
  }
  function updateTimer(){
    const ms = Date.now() - startTimeMs;
    timerEl.textContent = fmt(ms);
    levelBar.style.width = Math.min(100, approxLevel).toFixed(0) + '%';
  }

  function floatTo16BitPCM(float32Array){
    const out = new Int16Array(float32Array.length);
    for (let i=0;i<float32Array.length;i++){
      let s = Math.max(-1, Math.min(1, float32Array[i]));
      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return out;
  }

  function flattenFloat32(chunks){
    let total = 0;
    for (const c of chunks) total += c.length;
    const out = new Float32Array(total);
    let offset = 0;
    for (const c of chunks){
      out.set(c, offset);
      offset += c.length;
    }
    return out;
  }

  async function startRecording(){
    setError('');
    player.hidden = true;
    player.src = '';

    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, noiseSuppression: true, echoCancellation: true } });
    } catch (e) {
      setError('Microphone permission denied or unavailable.');
      return;
    }

    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });
    sampleRate = audioCtx.sampleRate;

    sourceNode = audioCtx.createMediaStreamSource(mediaStream);

    chunks.length = 0;
    approxLevel = 0;

    // Prefer AudioWorklet; fallback to ScriptProcessor for older Safari/Firefox
    try {
      const workletCode = `
        class CaptureProcessor extends AudioWorkletProcessor {
          constructor(){ super(); this._lastPeak=0; }
          process(inputs){
            const input = inputs[0];
            if (!input || !input[0]) return true;
            const ch0 = input[0];
            // copy to transferable buffer
            const buf = new Float32Array(ch0.length);
            buf.set(ch0);
            this.port.postMessage({ type:'data', samples: buf }, [buf.buffer]);
            // compute peak (for meter)
            let peak = 0;
            for (let i=0;i<ch0.length;i++){ const v = Math.abs(ch0[i]); if (v>peak) peak=v; }
            this.port.postMessage({ type:'peak', peak });
            return true;
          }
        }
        registerProcessor('capture-processor', CaptureProcessor);
      `;
      const blob = new Blob([workletCode], { type: 'application/javascript' });
      const url = URL.createObjectURL(blob);
      await audioCtx.audioWorklet.addModule(url);
      workletNode = new AudioWorkletNode(audioCtx, 'capture-processor');
      workletNode.port.onmessage = (e) => {
        const msg = e.data;
        if (msg.type === 'data') {
          chunks.push(new Float32Array(msg.samples));
        } else if (msg.type === 'peak') {
          approxLevel = Math.min(100, msg.peak * 160); // quick-n-dirty scaling
        }
      };
      sourceNode.connect(workletNode);
      // Worklet doesn't need to connect to destination to run; but some browsers pause if graph is silent:
      const silentGain = audioCtx.createGain(); silentGain.gain.value = 0;
      workletNode.connect(silentGain).connect(audioCtx.destination);
    } catch (err) {
      // Fallback: ScriptProcessorNode
      const bufferSize = 2048;
      scriptProcessor = audioCtx.createScriptProcessor(bufferSize, 1, 1);
      scriptProcessor.onaudioprocess = (e) => {
        const inBuf = e.inputBuffer.getChannelData(0);
        const copy = new Float32Array(inBuf.length);
        copy.set(inBuf);
        chunks.push(copy);
        // level
        let peak = 0; for (let i=0;i<inBuf.length;i++){ const v=Math.abs(inBuf[i]); if (v>peak) peak=v; }
        approxLevel = Math.min(100, peak * 160);
      };
      sourceNode.connect(scriptProcessor);
      scriptProcessor.connect(audioCtx.destination);
    }

    // UI
    recording = true;
    startTimeMs = Date.now();
    timerId = setInterval(updateTimer, 200);
    setStatus('Recording…');
    startBtn.disabled = true;
    stopBtn.disabled = false;
    saveBtn.disabled = true;
  }

  async function stopRecording(){
    if (!recording) return;
    recording = false;

    clearInterval(timerId);
    updateTimer();

    try{ if (workletNode){ workletNode.disconnect(); workletNode = null; 
  try { if (window.transcribeCurrentRecording) { await window.transcribeCurrentRecording(); } } catch(e) { /* ignore */ }
} }catch{}
    try{ if (scriptProcessor){ scriptProcessor.disconnect(); scriptProcessor = null; } }catch{}
    try{ if (sourceNode){ sourceNode.disconnect(); sourceNode = null; } }catch{}
    try{ if (audioCtx){ await audioCtx.close(); audioCtx = null; } }catch{}
    try{ if (mediaStream){ mediaStream.getTracks().forEach(t=>t.stop()); mediaStream=null; } }catch{}

    setStatus('Processing…');

    // Flatten to PCM and make a WAV URL for automatic preview
    const floatMono = flattenFloat32(chunks);
    const wavBlob = encodeWAV(floatMono, sampleRate);
    player.src = URL.createObjectURL(wavBlob);
    player.hidden = false;

    setStatus('Stopped. You can now download MP3.');
    startBtn.disabled = false;
    stopBtn.disabled  = true;
    saveBtn.disabled  = false;

    // Keep PCM samples in memory for MP3 export
    window.__REC_PCM__ = { floatMono, sampleRate };
  }

  function encodeWAV(float32, sampleRate){
    // 16-bit PCM WAV encoder
    const pcm16 = floatTo16BitPCM(float32);
    const buffer = new ArrayBuffer(44 + pcm16.length * 2);
    const view = new DataView(buffer);

    /* RIFF header */
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + pcm16.length * 2, true);
    writeString(view, 8, 'WAVE');
    /* fmt chunk */
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);             // PCM
    view.setUint16(20, 1, true);              // audio format = 1 (PCM)
    view.setUint16(22, 1, true);              // channels = 1
    view.setUint32(24, sampleRate, true);     // sample rate
    view.setUint32(28, sampleRate * 2, true); // byte rate (sr * ch * 2)
    view.setUint16(32, 2, true);              // block align (ch * 2)
    view.setUint16(34, 16, true);             // bits per sample
    /* data chunk */
    writeString(view, 36, 'data');
    view.setUint32(40, pcm16.length * 2, true);

    // PCM samples
    let offset = 44;
    for (let i=0;i<pcm16.length;i++, offset+=2){
      view.setInt16(offset, pcm16[i], true);
    }
    return new Blob([view], { type: 'audio/wav' });

    function writeString(dv, offset, s){ for (let i=0;i<s.length;i++) dv.setUint8(offset+i, s.charCodeAt(i)); }
  }

  function downloadBlob(blob, filename){
    const a = document.createElement('a');
    a.href = URL.createObjectURL(blob);
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    setTimeout(()=>{ URL.revokeObjectURL(a.href); a.remove(); }, 1000);
  }

  function encodeMP3(floatMono, sampleRate){
    if (typeof lamejs === 'undefined' || !lamejs.Mp3Encoder) throw new Error('MP3 encoder (lamejs) not loaded.');
    const mp3enc = new lamejs.Mp3Encoder(1, sampleRate, 128); // mono, sr, 128 kbps
    const samples = floatTo16BitPCM(floatMono);
    const blockSize = 1152; // MP3 frame size
    const mp3Data = [];
    for (let i=0; i<samples.length; i += blockSize){
      const chunk = samples.subarray(i, Math.min(i + blockSize, samples.length));
      const buf = mp3enc.encodeBuffer(chunk);
      if (buf.length > 0) mp3Data.push(new Int8Array(buf));
    }
    const end = mp3enc.flush();
    if (end.length > 0) mp3Data.push(new Int8Array(end));
    return new Blob(mp3Data, { type: 'audio/mpeg' });
  }

  startBtn.addEventListener('click', startRecording);
  stopBtn.addEventListener('click', stopRecording);
  saveBtn.addEventListener('click', () => {
    try{
      const data = window.__REC_PCM__;
      if (!data) throw new Error('No recording in memory.');
      const mp3Blob = encodeMP3(data.floatMono, data.sampleRate);
      downloadBlob(mp3Blob, 'recording.mp3');
      setStatus('MP3 downloaded.');
    }catch(e){
      console.error(e);
      setError('MP3 encode failed. Saving WAV instead.');
      // Fallback: let user download WAV
      const data = window.__REC_PCM__;
      if (data){
        const wavBlob = encodeWAV(data.floatMono, data.sampleRate);
        downloadBlob(wavBlob, 'recording.wav');
        setStatus('WAV downloaded.');
      }
    }
  });

  function setStatus(text){ statusEl.textContent = text; }
})();
</script>

    <!-- Auto-transcription output -->
    <section id="transcription-section" style="margin-top:1rem;">
      <h3>Transcript</h3>
      <pre id="transcript" style="white-space:pre-wrap; border:1px solid #ddd; padding:0.75rem; border-radius:8px; min-height:3em;"></pre>
    </section>
    

<script>
// ===== Speech-to-Text integration (FastAPI) =====
(function(){
  // Change this if your backend runs elsewhere:
  const API_URL = window.STT_URL || "http://localhost:8000/transcribe";

  // Basic helpers; if your page already has setStatus/setError, these no-ops will be ignored.
  if (typeof window.setStatus !== 'function') { window.setStatus = (msg)=>{ const el = document.querySelector('.status') || document.getElementById('status'); if (el) el.textContent = msg; }; }
  if (typeof window.setError !== 'function')  { window.setError  = (msg)=>{ console.error(msg); const el = document.querySelector('.error') || document.getElementById('error'); if (el) el.textContent = msg; }; }

  const transcriptEl = document.getElementById('transcript');

  async function transcribeCurrentRecording() {
    try {
      const data = window.__REC_PCM__;
      if (!data || !data.floatMono || !data.sampleRate) {
        throw new Error("No recorded audio in memory. Record first.");
      }
      // Expect your app to define encodeWAV(floatMono, sampleRate) – present in your original file.
      if (typeof window.encodeWAV !== 'function') {
        throw new Error("encodeWAV(...) is not defined on this page.");
      }

      const wavBlob = window.encodeWAV(data.floatMono, data.sampleRate);
      const fd = new FormData();
      fd.append('audio', new File([wavBlob], 'recording.wav', { type: 'audio/wav' }));

      setStatus('Uploading for transcription…');
      const res = await fetch(API_URL, { method: 'POST', body: fd });
      if (!res.ok) {
        const t = await res.text().catch(()=>'');
        throw new Error('STT request failed: ' + (t || res.status));
      }
      const json = await res.json();
      if (transcriptEl) transcriptEl.textContent = json.text || '(no speech detected)';
      setStatus('Transcribed.');
    } catch (e) {
      setError(e.message || String(e));
      setStatus('Idle');
    }
  }

  // Make available globally in case other code wants to call it
  window.transcribeCurrentRecording = transcribeCurrentRecording;
})();
</script>

</body>
</html>

//hello
